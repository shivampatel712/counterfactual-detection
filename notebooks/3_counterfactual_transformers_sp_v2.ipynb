{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers for Counterfactual Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This version has class weighted cross-entropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:53:27.008982Z",
     "iopub.status.busy": "2022-05-24T08:53:27.008726Z",
     "iopub.status.idle": "2022-05-24T08:53:27.089604Z",
     "shell.execute_reply": "2022-05-24T08:53:27.088735Z",
     "shell.execute_reply.started": "2022-05-24T08:53:27.008954Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:52:48.529152Z",
     "iopub.status.busy": "2022-05-24T08:52:48.528877Z",
     "iopub.status.idle": "2022-05-24T08:52:55.675803Z",
     "shell.execute_reply": "2022-05-24T08:52:55.675036Z",
     "shell.execute_reply.started": "2022-05-24T08:52:48.529124Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv', data_files='../input/counterfactualrecognition/subtask1_train_bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:52:55.678041Z",
     "iopub.status.busy": "2022-05-24T08:52:55.677596Z",
     "iopub.status.idle": "2022-05-24T08:53:00.150862Z",
     "shell.execute_reply": "2022-05-24T08:53:00.150139Z",
     "shell.execute_reply.started": "2022-05-24T08:52:55.678004Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=100)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:53:00.152613Z",
     "iopub.status.busy": "2022-05-24T08:53:00.152322Z",
     "iopub.status.idle": "2022-05-24T08:53:00.201402Z",
     "shell.execute_reply": "2022-05-24T08:53:00.200620Z",
     "shell.execute_reply.started": "2022-05-24T08:53:00.152575Z"
    }
   },
   "outputs": [],
   "source": [
    "train_test_dataset = tokenized_datasets[\"train\"].train_test_split(test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:53:00.203967Z",
     "iopub.status.busy": "2022-05-24T08:53:00.203691Z",
     "iopub.status.idle": "2022-05-24T08:53:00.213048Z",
     "shell.execute_reply": "2022-05-24T08:53:00.212311Z",
     "shell.execute_reply.started": "2022-05-24T08:53:00.203933Z"
    }
   },
   "outputs": [],
   "source": [
    "train_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:53:32.046241Z",
     "iopub.status.busy": "2022-05-24T08:53:32.045816Z",
     "iopub.status.idle": "2022-05-24T08:53:39.432209Z",
     "shell.execute_reply": "2022-05-24T08:53:39.431559Z",
     "shell.execute_reply.started": "2022-05-24T08:53:32.046204Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:54:10.358432Z",
     "iopub.status.busy": "2022-05-24T08:54:10.358119Z",
     "iopub.status.idle": "2022-05-24T08:54:12.693858Z",
     "shell.execute_reply": "2022-05-24T08:54:12.693210Z",
     "shell.execute_reply.started": "2022-05-24T08:54:10.358397Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "acc_metric = load_metric(\"accuracy\")\n",
    "f1_metric = load_metric(\"f1\")\n",
    "p_metric = load_metric(\"precision\")\n",
    "r_metric = load_metric(\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:54:14.842307Z",
     "iopub.status.busy": "2022-05-24T08:54:14.842045Z",
     "iopub.status.idle": "2022-05-24T08:54:14.848964Z",
     "shell.execute_reply": "2022-05-24T08:54:14.847517Z",
     "shell.execute_reply.started": "2022-05-24T08:54:14.842275Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels)\n",
    "    prec = p_metric.compute(predictions=predictions, references=labels)\n",
    "    rec = r_metric.compute(predictions=predictions, references=labels)\n",
    "    return {'accuracy':acc, 'f1':f1, 'precision':prec, 'recall':rec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:54:19.738005Z",
     "iopub.status.busy": "2022-05-24T08:54:19.737384Z",
     "iopub.status.idle": "2022-05-24T08:54:19.903634Z",
     "shell.execute_reply": "2022-05-24T08:54:19.902921Z",
     "shell.execute_reply.started": "2022-05-24T08:54:19.737966Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"cr_bert_trainer\", evaluation_strategy=\"epoch\", learning_rate=2e-5, num_train_epochs=8, save_steps=1500, report_to=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:54:23.640921Z",
     "iopub.status.busy": "2022-05-24T08:54:23.640377Z",
     "iopub.status.idle": "2022-05-24T08:54:24.210095Z",
     "shell.execute_reply": "2022-05-24T08:54:24.209211Z",
     "shell.execute_reply.started": "2022-05-24T08:54:23.640883Z"
    }
   },
   "outputs": [],
   "source": [
    "class CRTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 1.0]).to(device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = CRTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_test_dataset['train'],\n",
    "    eval_dataset=train_test_dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T08:54:49.852285Z",
     "iopub.status.busy": "2022-05-24T08:54:49.851993Z",
     "iopub.status.idle": "2022-05-24T09:19:26.992645Z",
     "shell.execute_reply": "2022-05-24T09:19:26.991797Z",
     "shell.execute_reply.started": "2022-05-24T08:54:49.852249Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:41:54.061036Z",
     "iopub.status.busy": "2022-05-24T09:41:54.060298Z",
     "iopub.status.idle": "2022-05-24T09:41:54.149862Z",
     "shell.execute_reply": "2022-05-24T09:41:54.149070Z",
     "shell.execute_reply.started": "2022-05-24T09:41:54.060995Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('../input/counterfactualrecognition/subtask1_test_bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:42:07.299045Z",
     "iopub.status.busy": "2022-05-24T09:42:07.298794Z",
     "iopub.status.idle": "2022-05-24T09:42:10.058457Z",
     "shell.execute_reply": "2022-05-24T09:42:10.057658Z",
     "shell.execute_reply.started": "2022-05-24T09:42:07.299015Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained('/kaggle/working/cr_bert_trainer/checkpoint-6000', num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:42:27.182373Z",
     "iopub.status.busy": "2022-05-24T09:42:27.182094Z",
     "iopub.status.idle": "2022-05-24T09:42:28.475549Z",
     "shell.execute_reply": "2022-05-24T09:42:28.474735Z",
     "shell.execute_reply.started": "2022-05-24T09:42:27.182327Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(list(test_df['text']), padding=\"max_length\", truncation=True, max_length=100, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:42:36.548923Z",
     "iopub.status.busy": "2022-05-24T09:42:36.548270Z",
     "iopub.status.idle": "2022-05-24T09:43:01.680136Z",
     "shell.execute_reply": "2022-05-24T09:43:01.679324Z",
     "shell.execute_reply.started": "2022-05-24T09:42:36.548887Z"
    }
   },
   "outputs": [],
   "source": [
    "test_size = len(test_df)\n",
    "batch_size = 8\n",
    "pred_labels = torch.zeros(test_size)\n",
    "\n",
    "for i in range(0, test_size, batch_size):\n",
    "    curr_inputs = {k:v[i:min(test_size, i+batch_size)].to(device)  for k, v in inputs.items()}\n",
    "    outputs = model(**curr_inputs)\n",
    "    pred_labels[i:min(test_size, i+batch_size)] = outputs.get('logits').argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:43:37.493926Z",
     "iopub.status.busy": "2022-05-24T09:43:37.493654Z",
     "iopub.status.idle": "2022-05-24T09:43:37.500889Z",
     "shell.execute_reply": "2022-05-24T09:43:37.499853Z",
     "shell.execute_reply.started": "2022-05-24T09:43:37.493895Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_labels = np.array(pred_labels.cpu().numpy())\n",
    "gold_labels = np.array(test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:43:40.488061Z",
     "iopub.status.busy": "2022-05-24T09:43:40.487624Z",
     "iopub.status.idle": "2022-05-24T09:43:40.530945Z",
     "shell.execute_reply": "2022-05-24T09:43:40.529974Z",
     "shell.execute_reply.started": "2022-05-24T09:43:40.487996Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "print('F1: ', f1_score(gold_labels, pred_labels))\n",
    "print('Accuracy: ', accuracy_score(gold_labels, pred_labels))\n",
    "print('Precision: ', precision_score(gold_labels, pred_labels))\n",
    "print('Recall: ', recall_score(gold_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positives and negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pred_labels * 10 + gold_labels\n",
    "tps = preds == 11\n",
    "fps = preds == 10\n",
    "fns = preds == 1\n",
    "tns = preds == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.array(test_df['text'])[fps])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
