{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers for Counterfactual Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:16.118205Z",
     "iopub.status.busy": "2022-05-19T17:22:16.117608Z",
     "iopub.status.idle": "2022-05-19T17:22:17.785072Z",
     "shell.execute_reply": "2022-05-19T17:22:17.784346Z",
     "shell.execute_reply.started": "2022-05-19T17:22:16.118114Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:21.060574Z",
     "iopub.status.busy": "2022-05-19T17:22:21.059910Z",
     "iopub.status.idle": "2022-05-19T17:22:26.189085Z",
     "shell.execute_reply": "2022-05-19T17:22:26.188340Z",
     "shell.execute_reply.started": "2022-05-19T17:22:21.060535Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv', data_files='../input/counterfactualrecognition/subtask1_train_bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:26.191514Z",
     "iopub.status.busy": "2022-05-19T17:22:26.190763Z",
     "iopub.status.idle": "2022-05-19T17:22:35.809358Z",
     "shell.execute_reply": "2022-05-19T17:22:35.808657Z",
     "shell.execute_reply.started": "2022-05-19T17:22:26.191474Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=100)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:35.812688Z",
     "iopub.status.busy": "2022-05-19T17:22:35.812492Z",
     "iopub.status.idle": "2022-05-19T17:22:35.870734Z",
     "shell.execute_reply": "2022-05-19T17:22:35.869964Z",
     "shell.execute_reply.started": "2022-05-19T17:22:35.812664Z"
    }
   },
   "outputs": [],
   "source": [
    "train_test_dataset = tokenized_datasets[\"train\"].train_test_split(test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:35.873532Z",
     "iopub.status.busy": "2022-05-19T17:22:35.873263Z",
     "iopub.status.idle": "2022-05-19T17:22:35.883246Z",
     "shell.execute_reply": "2022-05-19T17:22:35.882382Z",
     "shell.execute_reply.started": "2022-05-19T17:22:35.873497Z"
    }
   },
   "outputs": [],
   "source": [
    "train_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:35.885057Z",
     "iopub.status.busy": "2022-05-19T17:22:35.884789Z",
     "iopub.status.idle": "2022-05-19T17:22:52.057281Z",
     "shell.execute_reply": "2022-05-19T17:22:52.056544Z",
     "shell.execute_reply.started": "2022-05-19T17:22:35.885013Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:52.059330Z",
     "iopub.status.busy": "2022-05-19T17:22:52.059009Z",
     "iopub.status.idle": "2022-05-19T17:22:56.356031Z",
     "shell.execute_reply": "2022-05-19T17:22:56.355316Z",
     "shell.execute_reply.started": "2022-05-19T17:22:52.059292Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "acc_metric = load_metric(\"accuracy\")\n",
    "f1_metric = load_metric(\"f1\")\n",
    "p_metric = load_metric(\"precision\")\n",
    "r_metric = load_metric(\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:56.357807Z",
     "iopub.status.busy": "2022-05-19T17:22:56.357414Z",
     "iopub.status.idle": "2022-05-19T17:22:56.364084Z",
     "shell.execute_reply": "2022-05-19T17:22:56.363449Z",
     "shell.execute_reply.started": "2022-05-19T17:22:56.357769Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels)\n",
    "    prec = p_metric.compute(predictions=predictions, references=labels)\n",
    "    rec = r_metric.compute(predictions=predictions, references=labels)\n",
    "    return {'accuracy':acc, 'f1':f1, 'precision':prec, 'recall':rec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:56.365762Z",
     "iopub.status.busy": "2022-05-19T17:22:56.365297Z",
     "iopub.status.idle": "2022-05-19T17:22:56.529395Z",
     "shell.execute_reply": "2022-05-19T17:22:56.528719Z",
     "shell.execute_reply.started": "2022-05-19T17:22:56.365727Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"cr_bert_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:56.531037Z",
     "iopub.status.busy": "2022-05-19T17:22:56.530783Z",
     "iopub.status.idle": "2022-05-19T17:22:57.065985Z",
     "shell.execute_reply": "2022-05-19T17:22:57.065144Z",
     "shell.execute_reply.started": "2022-05-19T17:22:56.531005Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_test_dataset['train'],\n",
    "    eval_dataset=train_test_dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:57.070014Z",
     "iopub.status.busy": "2022-05-19T17:22:57.069182Z",
     "iopub.status.idle": "2022-05-19T17:22:57.074943Z",
     "shell.execute_reply": "2022-05-19T17:22:57.074138Z",
     "shell.execute_reply.started": "2022-05-19T17:22:57.069968Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:22:57.076574Z",
     "iopub.status.busy": "2022-05-19T17:22:57.076303Z",
     "iopub.status.idle": "2022-05-19T17:31:59.197872Z",
     "shell.execute_reply": "2022-05-19T17:31:59.197116Z",
     "shell.execute_reply.started": "2022-05-19T17:22:57.076537Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:32:24.608670Z",
     "iopub.status.busy": "2022-05-19T17:32:24.608382Z",
     "iopub.status.idle": "2022-05-19T17:32:24.674346Z",
     "shell.execute_reply": "2022-05-19T17:32:24.673581Z",
     "shell.execute_reply.started": "2022-05-19T17:32:24.608635Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('../input/counterfactualrecognition/subtask1_test_bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:45:52.692020Z",
     "iopub.status.busy": "2022-05-19T17:45:52.691761Z",
     "iopub.status.idle": "2022-05-19T17:45:58.072906Z",
     "shell.execute_reply": "2022-05-19T17:45:58.072204Z",
     "shell.execute_reply.started": "2022-05-19T17:45:52.691990Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained('/kaggle/working/cr_bert_trainer/checkpoint-4000', num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:46:04.781951Z",
     "iopub.status.busy": "2022-05-19T17:46:04.781696Z",
     "iopub.status.idle": "2022-05-19T17:46:06.010328Z",
     "shell.execute_reply": "2022-05-19T17:46:06.009518Z",
     "shell.execute_reply.started": "2022-05-19T17:46:04.781923Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(list(test_df['text']), padding=\"max_length\", truncation=True, max_length=100, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:51:20.067955Z",
     "iopub.status.busy": "2022-05-19T17:51:20.067699Z",
     "iopub.status.idle": "2022-05-19T17:51:44.832796Z",
     "shell.execute_reply": "2022-05-19T17:51:44.832097Z",
     "shell.execute_reply.started": "2022-05-19T17:51:20.067926Z"
    }
   },
   "outputs": [],
   "source": [
    "test_size = len(test_df)\n",
    "batch_size = 8\n",
    "pred_labels = torch.zeros(test_size)\n",
    "\n",
    "for i in range(0, test_size, batch_size):\n",
    "    curr_inputs = {k:v[i:min(test_size, i+batch_size)].to(device)  for k, v in inputs.items()}\n",
    "    outputs = model(**curr_inputs)\n",
    "    pred_labels[i:min(test_size, i+batch_size)] = outputs['logits'].argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:51:54.549191Z",
     "iopub.status.busy": "2022-05-19T17:51:54.548777Z",
     "iopub.status.idle": "2022-05-19T17:51:54.559707Z",
     "shell.execute_reply": "2022-05-19T17:51:54.558922Z",
     "shell.execute_reply.started": "2022-05-19T17:51:54.549152Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_labels = np.array(pred_labels.cpu().numpy())\n",
    "gold_labels = np.array(test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T17:51:57.235736Z",
     "iopub.status.busy": "2022-05-19T17:51:57.235479Z",
     "iopub.status.idle": "2022-05-19T17:51:57.263784Z",
     "shell.execute_reply": "2022-05-19T17:51:57.262969Z",
     "shell.execute_reply.started": "2022-05-19T17:51:57.235703Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "print('F1: ', f1_score(gold_labels, pred_labels))\n",
    "print('Accuracy: ', accuracy_score(gold_labels, pred_labels))\n",
    "print('Precision: ', precision_score(gold_labels, pred_labels))\n",
    "print('Recall: ', recall_score(gold_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
